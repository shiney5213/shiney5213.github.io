{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBoW(Continuous Bag of Words)\n",
    "- 주변 단어(Context Word)로 중심 단어(Center Word, target)를 예측하는 방법\n",
    "- 윈도우(Window): 중심 단어를 맞추기 위해 몇개의 주변 단어를 고려할지 정하는 범위\n",
    "- 슬라이딩 윈도우(Sliding Window): 학습을 위해 윈도우를 이동하면서 학습하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CBoW Model](../assets/img/nlp/3-Word2Vec-CBoW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델\n",
    "### 1)입력층\n",
    "- 윈도우(맥락 단어의 개수)가 2개인 경우 입력레이어 2개를 은닉층과 완전연결계층으로 연결\n",
    "- 가중치 W_in : 단어의 `분산 표현`-> 학습하면서 target단어를 잘 예측할 수 있도록 분산 표현이 갱신\n",
    "  \n",
    "### 2)은닉층\n",
    "- 입력층이 여러개인 경우 전체의 `평균`으로 구함\n",
    "- 입력층의 단어의 개수보다 은닉층 뉴런의 개수가 적어야 함 \n",
    "  > 단어 예측에 필요한 정보를 간결하게 얻을 수 있음 <br>\n",
    "  > 결과적으로 희소벡터가 아닌 밀집 벡터 표현을 얻을 수 있음.\n",
    "\n",
    "### 3)출력층\n",
    "- 출력층 뉴런의 개수: 단어의 개수와 동일\n",
    "- softmax함수를 사용하여 각 단어가 target일 확률로 변환\n",
    "\n",
    "## embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코딩\n",
    "- https://github.com/rickiepark/nlp-with-pytorch/blob/main/chapter_5/5_2_CBOW/5_2_Continuous_Bag_of_Words_CBOW.ipynb 참고\n",
    "### 1. data\n",
    "- dataset : http://bit.ly/2T5iU8J 에서 메리 셸리의 소설 [프랑켄슈타인]의 디지털 버전을 받아 구축한 텍스트 데이터셋 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import nltk.data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from  tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = Namespace(\n",
    "    raw_dataset_txt = \"../assets/data/nlp/3_Word2Vec_CBoW_frankenstein.txt\",\n",
    "    window_size = 5,\n",
    "    train_proportion = 0.7,\n",
    "    val_proportion = 0.15,\n",
    "    test_proportion = 0.15,\n",
    "    output_munged_csv=\"../assets/data/nlp/3_Word2Vec_CBoW_frankenstein_with_splits.csv\",\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1) data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shiney\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206\n",
      "sample:  I dare not expect such success, yet I cannot bear to look on the reverse of the picture.\n"
     ]
    }
   ],
   "source": [
    "# Split the raw text into sentences\n",
    "tokenizer =nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "with open(args.raw_dataset_txt, encoding = 'UTF8') as fp:\n",
    "    book = fp.read()\n",
    "sentences = tokenizer.tokenize(book)\n",
    "\n",
    "print(len(sentences))\n",
    "print(\"sample: \", sentences[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cleaning:  Again shall you raise the funeral wail, and the sound of your lamentations shall again and again be heard!\n",
      "after cleaning:  again shall you raise the funeral wail , and the sound of your lamentations shall again and again be heard ! \n"
     ]
    }
   ],
   "source": [
    "# clean sentences\n",
    "def preprocess_text(text):\n",
    "    text = ' '.join(word.lower() for word in text.split(\" \"))\n",
    "    text = re.sub(r\"([.,!?])\", r\" \\1 \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.,!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "cleaned_sentences = [preprocess_text(sentence) for sentence in sentences]\n",
    "\n",
    "num = 1100\n",
    "print(\"before cleaning: \", sentences[num])\n",
    "print(\"after cleaning: \", cleaned_sentences[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) CBow dataset 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3206/3206 [00:00<00:00, 54484.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206 ->  90570\n",
      "sample: ('<MASK>', '<MASK>', '<MASK>', '<MASK>', '<MASK>', 'the', 'project', 'gutenberg', 'ebook', 'of', 'frankenstein')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Global vars\n",
    "MASK_TOKEN = \"<MASK>\"\n",
    "\n",
    "# Create windows\n",
    "flatten = lambda outer_list: [item for inner_list in outer_list for item in inner_list]\n",
    "windows = flatten([list(nltk.ngrams([MASK_TOKEN] * args.window_size + sentence.split(' ') + \\\n",
    "    [MASK_TOKEN] * args.window_size, args.window_size * 2 + 1)) \\\n",
    "    for sentence in tqdm(cleaned_sentences)])\n",
    "\n",
    "\n",
    "print(len(cleaned_sentences) ,'-> ',len(windows))\n",
    "print('sample:', windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90570/90570 [00:00<00:00, 180228.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90570\n",
      "['project gutenberg ebook of frankenstein', 'the']\n",
      "['the gutenberg ebook of frankenstein ,', 'project']\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for window in tqdm(windows):\n",
    "    target_token = window[args.window_size]\n",
    "    context = []\n",
    "    for i, token in enumerate(window):\n",
    "        if token == MASK_TOKEN or i == args.window_size:\n",
    "            continue\n",
    "        else:\n",
    "            context.append(token)\n",
    "    data.append([' '.join(token for token in context),target_token])\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])\n",
    "print(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>project gutenberg ebook of frankenstein</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gutenberg ebook of frankenstein ,</td>\n",
       "      <td>project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the project ebook of frankenstein , by</td>\n",
       "      <td>gutenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the project gutenberg of frankenstein , by mary</td>\n",
       "      <td>ebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the project gutenberg ebook frankenstein , by ...</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context     target\n",
       "0            project gutenberg ebook of frankenstein        the\n",
       "1              the gutenberg ebook of frankenstein ,    project\n",
       "2             the project ebook of frankenstein , by  gutenberg\n",
       "3    the project gutenberg of frankenstein , by mary      ebook\n",
       "4  the project gutenberg ebook frankenstein , by ...         of"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe\n",
    "cbow_data = pd.DataFrame(data, columns = ['context', 'target'])\n",
    "\n",
    "cbow_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90565</th>\n",
       "      <td>our email newsletter to hear new ebooks .</td>\n",
       "      <td>about</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90566</th>\n",
       "      <td>email newsletter to hear about ebooks .</td>\n",
       "      <td>new</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90567</th>\n",
       "      <td>newsletter to hear about new .</td>\n",
       "      <td>ebooks</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90568</th>\n",
       "      <td>to hear about new ebooks</td>\n",
       "      <td>.</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90569</th>\n",
       "      <td>hear about new ebooks .</td>\n",
       "      <td></td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          context  target split\n",
       "90565  our email newsletter to hear new ebooks .    about  test\n",
       "90566    email newsletter to hear about ebooks .      new  test\n",
       "90567             newsletter to hear about new .   ebooks  test\n",
       "90568                   to hear about new ebooks        .  test\n",
       "90569                     hear about new ebooks .          test"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split train, test, val\n",
    "n = len(cbow_data)\n",
    "\n",
    "def get_split(row_num):\n",
    "    if row_num <= n * args.train_proportion:\n",
    "        return 'train'\n",
    "    elif (row_num > n * args.train_proportion) and (row_num <= n *  args.train_proportion + n * args.val_proportion):\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'test'\n",
    "\n",
    "cbow_data['split'] = cbow_data.apply(lambda row: get_split(row.name), axis = 1)\n",
    "\n",
    "cbow_data.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write split data to file\n",
    "cbow_data.to_csv(args.output_munged_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vocabulary, Vectorizer, DataLoader 클래스\n",
    "- 텍스트 입력을 벡터의 미니배치로 바꾸기\n",
    "> 1. 토큰을 정수로 매핑하기\n",
    "> 2. 앞의 각 데이터 포인터에 적용해 벡터 형태로 변환-> 고정된 길이로(padding 이용)\n",
    "> 3. 벡터로 변환한 데이터 포인트를 미니배치로 모음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  토큰을 정수로 매핑하기-> Vocabulary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulraty\n",
    "class Vocabulary(object):\n",
    "    \"\"\"매핑을 위해 텍스트를 처리하고 어휘 사전을 만드는 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, token_to_idx = None, mask_token = \"<MASK>\", add_unk = True, unk_token =\">UNK>\"):\n",
    "        \"\"\"\n",
    "        매개변수:\n",
    "            token_to_idx(dict) : 기존 토큰-인텍스 매핑 딕셔너리\n",
    "            mask_token(str) : Vocabulary에 추가할 MASK 토큰\n",
    "                            -> 모델 파라미터를 업데이트 하는데 사용하지 않는 위치를 나타냄\n",
    "            add_unk(bool) : UNK 토큰을 추가할지 지정하는 플래그\n",
    "            unk_token(str) : Vocabulary에 추가할 UNK 토큰\n",
    "        \"\"\"\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        self._token_to_idx = token_to_idx\n",
    "\n",
    "        self._idx_to_token = {idx : token for token, idx in self._token_to_idx.items()}\n",
    "\n",
    "        self._add_unk = add_unk\n",
    "        self._unk_token = unk_token\n",
    "        self._mask_token = mask_token\n",
    "\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(unk_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        \"\"\" 직렬화할 수 있는 딕셔너리를 반환합니다.\"\"\"\n",
    "        return {'token_to_idx': self._token_to_idx,\n",
    "                'add_unk': self._add_unk,\n",
    "                'unk_token': self._unk_token,\n",
    "                'mask_token': self._mask_token}\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        \"\"\" 직렬화된 딕셔너리에서 Vocabulary 객체를 만듭니다\"\"\"\n",
    "        return cls(**contents)\n",
    "\n",
    "    def add_token(self, token):\n",
    "        \"\"\"토큰을 기반으로 매핑 딕셔너리를 업데이트합니다\n",
    "        매개변수:\n",
    "            token(str): Vocabulary에 추가할 토큰\n",
    "        반환값:\n",
    "            index(int): 토큰에 상응하는 정수\n",
    "        \"\"\"\n",
    "\n",
    "        if token in self._token_to_idx:\n",
    "            index = len(self._token_to_idx)\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "\n",
    "    def add_many(self, tokens):\n",
    "        \"\"\"토큰 리스트를 Vocabulary에 추가합니다.\n",
    "        매개변수:\n",
    "            token(list): 문자열 토큰 리스트\n",
    "        반환값:\n",
    "            indeces(list): 토큰 리스트에 상응하는 인텍스 리스트\n",
    "        \"\"\"\n",
    "        return [self.add_token(token) for token in tokens]\n",
    "\n",
    "    def lookup_token(self, token):\n",
    "        \"\"\"토큰에 대응되는 인덱스를 추출합니다.  토큰이 없으면 UNK 인덱스를 반환합니다.\n",
    "        매개변수:\n",
    "            token(str): 찾을 토큰\n",
    "        반환값:\n",
    "            index(int): 토큰에 해당하는 인덱스\n",
    "        노트:\n",
    "            UNK 토큰을 사용하려면(Vocavulary에 추가하기 위해) 'unk_index'가 0보다 커야 합니다\n",
    "        \"\"\"\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        \"\"\" 인덱스에 해당하는 토큰을 반환합니다. \n",
    "        매개변수:\n",
    "            index(int): 찾을 인덱스\n",
    "        반환값:\n",
    "            token(str): 인덱스에 해당하는 토큰\n",
    "        에러:\n",
    "            KeyError : 인덱스가 Vocabulary에 없을 때 발생합니다.\n",
    "        \"\"\"\n",
    "\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in Vocabulary\" % index)\n",
    "        return self._idx_to_token[index]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\" % len(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 앞의 각 데이터 포인터에 적용해 벡터 형태로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWVectorizer(object):\n",
    "    \"\"\" 어휘 사전을 생성하고 관리합니다.\"\"\"\n",
    "    def __init__(self, cbow_vocab):\n",
    "        \"\"\" \n",
    "        매개변수:\n",
    "            cbow_vocab(Vocabulary) : 단어에 정수를 매핑합니다.\n",
    "        \"\"\"\n",
    "\n",
    "        self.cbow_vocab = cbow_vocab\n",
    "    def vectorize(self, context, vector_length = -1):\n",
    "        \"\"\" \n",
    "        매개변수:\n",
    "            context(str) : 공백으로 나누어진 단어 문자열\n",
    "            vector_length(int) : 인덱스 벡터의 길이 매개변수\n",
    "        \"\"\"\n",
    "\n",
    "        indices = [self.cbow_vocab.lookup_token(token) for token in context.split(' ')]\n",
    "        if vector_length < 0:\n",
    "            vector_length = len(indices)\n",
    "\n",
    "        out_vector = np.zeros(vector_length, dtype = np.int64)\n",
    "        out_vector[:len(indices)] = indices \n",
    "        out_vector[len(indices):] = self.cbow_vocab.mask_index\n",
    "\n",
    "        return out_vector\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, cbow_df):\n",
    "        \"\"\" 데이터셋 데이터프레임에서 Vectorizer 객체를 만듭니다\n",
    "        \n",
    "        매개변수:\n",
    "            cbow_df(pandas.DataFrame) : 타깃 데이터셋\n",
    "        반환값:\n",
    "            CBOWVectorizer 객체\n",
    "        \"\"\"\n",
    "        cbow_vocab = Vocabulary()\n",
    "        for index, row in cbow_df.iterrows():\n",
    "            for token in row.context.split(' '):\n",
    "                cbow_vocab.add_token(token)\n",
    "            cbow_vocab.add_token(row.target)\n",
    "\n",
    "        return cls(cbow_vocab)\n",
    "\n",
    "    @classmethod\n",
    "    def from_serializable(cls, contents):\n",
    "        cbow_vocab = Vocabulary.from_serializagle(contents['cbow_vocab'])\n",
    "        return cls(cbow_vocab = cbow_vocab)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'cbow_vocab': self.cbow_vocab.to_serializable()}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)  벡터로 변환한 데이터 포인트를 미니배치로 모음  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CBOWDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWDataset(Dataset):\n",
    "    def __init__(self, cbow_df, vectorizer):\n",
    "        \"\"\" \n",
    "        매개변수:\n",
    "            cbow_df(pandas.DataFrame) : 데이터셋\n",
    "            vectorizer(CBOWVectorizer) : 데이터셋에서 만든 CBOWVectorizer 객체\n",
    "        \"\"\"\n",
    "\n",
    "        self.cbow_df = cbow_df\n",
    "        self._vectorizer = vectorizer\n",
    "\n",
    "        measure_len = lambda context: len(context.split(\" \"))\n",
    "        self._max_seq_length = max(map(measure_len, cbow_df.context))\n",
    "\n",
    "        self.train_df = self.cbow_df[self.cbow_df.split=='train']\n",
    "        self.train_size = len(self.train_df)\n",
    "\n",
    "        self.val_df = self.cbow_df[self.cbow_df.split=='val']\n",
    "        self.val_size = len(self.val_df)\n",
    "\n",
    "        self.test_df = self.cbow_df[self.cbow_df.split=='test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                            'val': (self.val_df, self.val_size),\n",
    "                            'test': (self.test_df, self.test_df), }\n",
    "\n",
    "        self.set_split('train')\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, cbow_csv):\n",
    "        \"\"\" 데이터셋을 로드하고 처음부터 새로운 Vectorizer 만들기\n",
    "        매개변수:\n",
    "            cbow_csv(str) : 데이터셋의 위치\n",
    "        반환값:\n",
    "            CBOWDataset의 인스턴스\n",
    "        \"\"\"\n",
    "        cbow_df = pd.read_csv(cbow_csv)\n",
    "        train_cbow_df = cbow_df[cbow_df.split ==\"train\"] \n",
    "        return cls(cbow_df, CBOWVectorizer.from_dataframe(train_cbow_df))\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, cbow_csv, vectorizer_filepath):\n",
    "        \"\"\" 데이터셋을 로드하고 새로운 CBOWVectorizer 객체를 만듭니다.\n",
    "        캐시뒨 CBOWVectorizer 객체를 재사용할 때 사용합니다.\n",
    "        매개변수:\n",
    "            cbow_csv(str) : 데이셋의 위치\n",
    "            vectorizer_filepath(str) : CBOWVectorizer 객체의 저장 위치\n",
    "        반환값:\n",
    "            CBOWVectorizer의 인스턴스\n",
    "        \"\"\"\n",
    "        cbow_df = pd.readcsv(cbow_csv)\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(cbow_df, vectorizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        \"\"\" 파일에서 CBOWVectorizer 객체를 로드하는 정적 메서드\n",
    "        \n",
    "        매개변수:\n",
    "            vectorizer-filepath(str) : 직렬화된 CBOWVectorizer 객체의 위치\n",
    "        반환값:\n",
    "            CBOWVectorizer의 인스턴스\n",
    "        \"\"\"\n",
    "\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return CBOWVectorizer.from_serializable(json.load(fp))\n",
    "\n",
    "    def save_vectorizer(self,vectorizer_filepath):\n",
    "        \"\"\" CBOWVectorizer 객체를 json형태로 디스트에 저장합니다.\n",
    "        매개변수:\n",
    "            vectorizer_filepath(str) : CBOWVectorizer 객체의저장 위치\n",
    "        \"\"\"\n",
    "        with open(vectorizer_filepath,'w') as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "\n",
    "    def get_vectorizer(self):\n",
    "        \"\"\" 벡터 변환 객체를 반환합니다\"\"\"\n",
    "        return self._vectorizer\n",
    "\n",
    "    def set_split(self, split = 'train'):\n",
    "        \"\"\" 데이터프레임에 있는 열을 사용해 분할 세트를 선택합니다.\"\"\"\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        \"\"\" 파이토피 데이터셋의 주요 진입 메서트\n",
    "        매개변수:\n",
    "            index(int) : 데이터 포인트의 인덱스\n",
    "        반환값:\n",
    "            데이터포이트의 특성(x_data)과 레이블(y_target)로 이루어진 딕셔너리\n",
    "        \"\"\"\n",
    "        row = self._target_df.iloc[index]\n",
    "\n",
    "        context_vector = self._vectorizer.vectorize(row.context, self._max_seq_length)\n",
    "        target_index = self._vectorizer.cbow_vocab.lookup_token(row.target)\n",
    "\n",
    "        return {'x_data': context_vector,\n",
    "                'y_target': target_index}\n",
    "\n",
    "    def get_num_batches(self, batch_size):\n",
    "        \"\"\" 배치 크기가 주어지면 데이터셋으로 만들수있는 배치 개수를 반환합니다.\n",
    "        \n",
    "        매개변수:\n",
    "            batch_size(int)\n",
    "        반환값:\n",
    "            배치 개수\n",
    "        \"\"\"\n",
    "        return len(self) // batch_size\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle = True, drop_last = True, device = 'cpu'):\n",
    "    \"\"\" 파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\n",
    "    각 텐서를 지정된 장치로 이동합니다.\n",
    "    \"\"\"\n",
    "    dataloader = DataLoader(dataset = dataset,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = shuffle,\n",
    "                            drop_last = drop_last)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict ={}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CBOWClassifier 모델\n",
    "\n",
    "- 과정\n",
    "> 1. Embedding층을 사용해 문맥의 단어를 나타내는 인텍스를 각 단어에 대한 벡터로 만들기\n",
    "> 2. 전반적인 문맥을 감지하도록 벡터 결합\n",
    "> 3. Linear층에서 문맥 벡터를 사용해 예측 벡터 계산-> 예측 벡터: 전체 어휘 사전에 대한 확률 분포 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOWClassifier(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size, padding_idx = 0):\n",
    "        \"\"\" \n",
    "        매개변수: \n",
    "            vocabulary_size(int) : 어휘 사전 크기, 임베딩 개수와 예측 벡터 크기를 결정\n",
    "            embedding_size(int): 임베딩 크기\n",
    "            padding_idx(int): 기본값 0, 임베딩은 이 인덱스를 사용하지 않습니다.\n",
    "        \"\"\"\n",
    "        super(CBOWClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings = vocabulary_size,  # 6173 -> 닥셔너리 개수\n",
    "                                        embedding_dim = embedding_size,  # 300-> 은닉층 hidden node 개수\n",
    "                                        padding_idx = padding_idx\n",
    "                                    ) \n",
    "        self.fc1 = nn.Linear(in_features = embedding_size,\n",
    "                            out_features= vocabulary_size) # 6173\n",
    "\n",
    "    def forward(self, x_in, apply_softmax = False):\n",
    "        \"\"\" 분류기의 정방향 계산\n",
    "        \n",
    "        매개변수:\n",
    "            x_in(torch.Tensor): 입력 데이터 텐서\n",
    "                x_in.shape는 (batch, input_dim)입니다\n",
    "            apply_softmax(bool): 소프트맥스 활성화 함수를 위한 플래그\n",
    "                크로스 엔트로피 손신을 사용하려면 False로 지정합니다.\n",
    "        반환값:\n",
    "            결과 텐서.tensor.shape는 (batch, output_dim)입니다\n",
    "        \"\"\"\n",
    "        x_embedded_sum = self.embedding(x_in).sum(dim =1)   # 문맥 단어 10개의 embedding값을 합치기\n",
    "        y_out = self.fc1(x_embedded_sum)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim = 1)\n",
    "\n",
    "        return y_out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train\n",
    "\n",
    "- 과정\n",
    "> 1. dataset, Vectorizer 객체, 모델, 손실함수, 옵티마이저 초기화\n",
    "> 2.특정 에포크 횟수 동안 훈련 세트와 검증 셋트 반복\n",
    "> 3. 훈련 세트로 손실함수를 최적화하고, 검증 세트로 훈련 과정을 평가 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) 헬퍼함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\" 훈련 상태를 업데이트합니다\n",
    "    \n",
    "    Components:\n",
    "    - 조기 종료: 과대적합 방지\n",
    "    - 모델 체크포인트: 더 나은 모델을 저장합니다.\n",
    "    \n",
    "    : param args: 메일 매개변수\n",
    "    : param model: 훈련할 모델\n",
    "    : param train_state: 훈련 상태를 담은 딕셔너리\n",
    "    : return:\n",
    "        새로운 훈련 상태\n",
    "    \"\"\"\n",
    "\n",
    "    # 적어도 한번 모델을 저장합니다.\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "    \n",
    "    # 성능이 향상되면 모델을 저장합니다.\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # 손실이 나빠지면\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # 조기종료 단계 업데이트\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # 손실이 감소하면\n",
    "        else:\n",
    "            # 최상의 모델 저장\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # 조기 종료 단계 재 설정\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # 조기 종료 여부 확인\n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indeces = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indeces, y_target).sum().item()\n",
    "    return n_correct/ len(y_pred_indeces) * 100\n",
    "\n",
    "# 일반 유틸리티\n",
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # 날짜와 경로 정보\n",
    "    cbow_csv = \"../assets/data/nlp/3_Word2Vec_CBoW_frankenstein_with_splits.csv\",\n",
    "    vectorizer_file = \"cbow_vectorizer.json\",\n",
    "    model_state_file = \"cbow_model.pth\",\n",
    "    save_dir = \"../assets/model/nlp/cbow\",\n",
    "\n",
    "    # 모델 하이퍼파라미터\n",
    "    embedding_size = 300,\n",
    "\n",
    "    # 훈련 하이퍼파라미터\n",
    "    seed =42,\n",
    "    num_epochs = 100,\n",
    "    learning_rate = 0.001,\n",
    "    batch_size = 128,\n",
    "    early_stopping_criteria = 5,\n",
    "\n",
    "    # 실행 옵션\n",
    "    cuda = True,\n",
    "    catch_keyboard_interrupt = True,\n",
    "    reload_from_files = False,\n",
    "    expand_filepaths_to_save_dir = True,\n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 경로:\n",
      "\t../assets/model/nlp/cbow\\cbow_vectorizer.json\n",
      "\t../assets/model/nlp/cbow\\cbow_model.pth\n",
      "CUDA 사용여부: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train_state = make_train_state(args)\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.vectorizer_file = os.path.join(args.save_dir, args.vectorizer_file)\n",
    "    args.model_state_file = os.path.join(args.save_dir, args.model_state_file)\n",
    "\n",
    "print('파일 경로:')\n",
    "print('\\t{}'.format(args.vectorizer_file))\n",
    "print('\\t{}'.format(args.model_state_file))\n",
    "\n",
    "\n",
    "# CUDA check\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')\n",
    "print(\"CUDA 사용여부: {}\".format(args.cuda))\n",
    "\n",
    "# 재현성을 위한 시드 설정\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# 디렉토리 처리\n",
    "handle_dirs(args.save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 데이터셋, 모델, 소실, 옵티마이저, 훈련 상태 딕셔너리 만들기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋을 로드하고 vectorizer를 만듭니다\n"
     ]
    }
   ],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss':[],\n",
    "            'val_acc': [],\n",
    "            'test_loss' : -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# dataset, Vectorizer\n",
    "if args.reload_from_files:\n",
    "    print('데이터셋과 vectorizer를 로드합니다')\n",
    "    dataset = CBOWDataset.load_dataset_and_load_vectorizer(args.cbow_csv, args.vectorizer_file)\n",
    "\n",
    "else:\n",
    "    print('데이터셋을 로드하고 vectorizer를 만듭니다')\n",
    "    dataset = CBOWDataset.load_dataset_and_make_vectorizer(args.cbow_csv)\n",
    "    dataset.save_vectorizer(args.vectorizer_file)\n",
    "\n",
    "vectorizer = dataset.get_vectorizer()\n",
    "\n",
    "# model\n",
    "classifier = CBOWClassifier(vocabulary_size= len(vectorizer.cbow_vocab),\n",
    "                            embedding_size = args.embedding_size)\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "\n",
    "# loss function, optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(classifier.parameters(), lr = args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer = optimizer,\n",
    "                                                mode = 'min',\n",
    "                                                factor = 0.5,\n",
    "                                                patience = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<MASK>', '>UNK>', 'project', 'gutenberg', 'ebook', 'of', 'frankenstein', 'the', ',', 'by']\n"
     ]
    }
   ],
   "source": [
    "# vectorizer 확인\n",
    "idx = list(range(0,10))\n",
    "print([vectorizer.cbow_vocab.lookup_index(i) for i in idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size 6173\n",
      "dict_keys(['token_to_idx', 'add_unk', 'unk_token', 'mask_token'])\n",
      "frankenstein 의 idx: 6\n"
     ]
    }
   ],
   "source": [
    "# cbow_vocab 확인\n",
    "print('vocabulary_size', len(vectorizer.cbow_vocab))\n",
    "\n",
    "print(vectorizer.cbow_vocab.to_serializable().keys())\n",
    "token = 'frankenstein'\n",
    "print( token,'의 idx:', vectorizer.cbow_vocab.to_serializable()['token_to_idx'][token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOWClassifier(\n",
      "  (embedding): Embedding(6173, 300, padding_idx=0)\n",
      "  (fc1): Linear(in_features=300, out_features=6173, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# model 확인\n",
    "print(classifier)\n",
    "# 6173 : vocabulary_size\n",
    "# 300 : embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_routine:   0%|          | 0/100 [00:34<?, ?it/s]\n",
      "split = train:   0%|          | 0/495 [00:34<?, ?it/s]\n",
      "split = val:   0%|          | 0/106 [00:34<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch_bar = tqdm(desc = 'training_routine',\n",
    "                                total = args.num_epochs,\n",
    "                                position = 0)\n",
    "\n",
    "dataset.set_split('train')\n",
    "train_bar = tqdm(desc = 'split = train',\n",
    "                                total = dataset.get_num_batches(args.batch_size),\n",
    "                                position = 1,\n",
    "                                leave = True)\n",
    "\n",
    "dataset.set_split('val')\n",
    "val_bar = tqdm(desc = 'split = val',\n",
    "                                total = dataset.get_num_batches(args.batch_size),\n",
    "                                position = 1,\n",
    "                                leave = True)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n",
      "[2738, 293, 399, 650, 5, 4349, 8, 7, 1805, 5]\n",
      "10 ['views', 'he', 'had', 'taken', 'of', 'society', ',', 'the', 'means', 'of']\n"
     ]
    }
   ],
   "source": [
    "# input 값 확인\n",
    "# 문맥단어가 5이기 때문에 5 * 2 = 10개의 단어가 input이 됨\n",
    "dataset.set_split('train')\n",
    "batch_generator = generate_batches(dataset,\n",
    "                                    batch_size = args.batch_size,\n",
    "                                    device = args.device)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_acc = 0.0\n",
    "classifier.train()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    print(batch_dict['x_data'].shape)\n",
    "    if batch_index == 0:\n",
    "        data = batch_dict['x_data'][0]\n",
    "        data_idx = data.tolist()\n",
    "        print(data_idx)\n",
    "\n",
    "        token = [vectorizer.cbow_vocab._idx_to_token[i] for i in data_idx]\n",
    "        print(len(token), token)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training_routine: 100%|██████████| 100/100 [33:00<00:00, 10.68s/it]  "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # 훈련 세트에 대한 순회\n",
    "        # 훈련 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
    "        dataset.set_split('train')\n",
    "        batch_generator = generate_batches(dataset,\n",
    "                                            batch_size = args.batch_size,\n",
    "                                            device = args.device)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # 훈련 과정\n",
    "            # --------------------------------------------\n",
    "            # 단계 1. 그레디언트를 0으로 초기화\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 단계 2. 출력을 계산\n",
    "            y_pred = classifier(x_in = batch_dict['x_data'])\n",
    "\n",
    "            # 단계 3. 손실을 계산\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss)/(batch_index + 1)\n",
    "\n",
    "            # 단계 4. 손실을 사용해 그레이디언트 계산\n",
    "            loss.backward()\n",
    "\n",
    "            # 단계 5. 옵티마이저로 가중치를 업데이트\n",
    "            optimizer.step()\n",
    "            # --------------------------------------------\n",
    "\n",
    "            # 정확도 계산\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # 진행바 업데이트\n",
    "            train_bar.set_postfix(loss = running_loss,\n",
    "                                    acc = running_acc,\n",
    "                                    epoch = epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # 검증 세트에 대한 순회\n",
    "        # 검증 세트와 배치 제너레이터 준비, 손실과 정확도를 0으로 설정\n",
    "        dataset.set_split('val')\n",
    "        batch_generator = generate_batches(dataset,\n",
    "                                            batch_size = args.batch_size,\n",
    "                                            device = args.device)\n",
    "\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(batch_generator):\n",
    "            # 검증 과정\n",
    "            # --------------------------------------------\n",
    "            # 단계 1. 출력을 계산\n",
    "            y_pred = classifier(x_in = batch_dict['x_data'])\n",
    "\n",
    "            # 단계 2. 손실을 계산\n",
    "            loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss)/(batch_index + 1)\n",
    "\n",
    "            # 단계 3. 정확도 계산\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "            # --------------------------------------------\n",
    "\n",
    "            # 진행바 업데이트\n",
    "            val_bar.set_postfix(loss = running_loss,\n",
    "                                    acc = running_acc,\n",
    "                                    epoch = epoch_index)\n",
    "            val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args = args,\n",
    "                                        model = classifier,\n",
    "                                        train_state = train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Exiting loop')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab  import plt\n",
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 100\n",
      "val 100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_loss, val_loss 비교\n",
    "train_loss = train_state['train_loss']\n",
    "val_loss = train_state['val_loss']\n",
    "\n",
    "print('train', len(train_loss))\n",
    "print('val', len(val_loss))\n",
    "\n",
    " \n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, 101)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(arange(0, 101, 2))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m running_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m     13\u001b[0m classifier\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_index, batch_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_generator):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# 출력을 계산합니다\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m  classifier(x_in\u001b[38;5;241m=\u001b[39mbatch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_data\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# 손실을 계산합니다\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[42], line 118\u001b[0m, in \u001b[0;36mgenerate_batches\u001b[1;34m(dataset, batch_size, shuffle, drop_last, device)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_batches\u001b[39m(dataset, batch_size, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" 파이토치 DataLoader를 감싸고 있는 제너레이터 함수.\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    각 텐서를 지정된 장치로 이동합니다.\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m data_dict \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m    124\u001b[0m         out_data_dict \u001b[38;5;241m=\u001b[39m{}\n",
      "File \u001b[1;32mc:\\Users\\shiney\\anaconda3\\envs\\book\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:350\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[0;32m    349\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 350\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiney\\anaconda3\\envs\\book\\lib\\site-packages\\torch\\utils\\data\\sampler.py:142\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement, \u001b[39mbool\u001b[39m):\n\u001b[0;32m    140\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shiney\\anaconda3\\envs\\book\\lib\\site-packages\\torch\\utils\\data\\sampler.py:149\u001b[0m, in \u001b[0;36mRandomSampler.num_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnum_samples\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m    147\u001b[0m     \u001b[39m# dataset size might change at runtime\u001b[39;00m\n\u001b[0;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_source)\n\u001b[0;32m    150\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_samples\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# 가장 좋은 모델을 사용헤 테스트 세트의 손실과 정확도 계산\n",
    "classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "classifier = classifier.to(args.device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "dataset.set_split('test')\n",
    "batch_generator = generate_batches(dataset, \n",
    "                                   batch_size=args.batch_size, \n",
    "                                   device=args.device)\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    # 출력을 계산합니다\n",
    "    y_pred =  classifier(x_in=batch_dict['x_data'])\n",
    "    \n",
    "    # 손실을 계산합니다\n",
    "    loss = loss_func(y_pred, batch_dict['y_target'])\n",
    "    loss_t = loss.item()\n",
    "    running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "    # 정확도를 계산합니다\n",
    "    acc_t = compute_accuracy(y_pred, batch_dict['y_target'])\n",
    "    running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set loss: -1\n",
      "test_set acc: -1\n"
     ]
    }
   ],
   "source": [
    "print('test set loss: {}'.format(train_state['test_loss']))\n",
    "print('test_set acc: {}'.format(train_state['test_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) embedding 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(results):\n",
    "    \"\"\" \n",
    "    임베딩 결과를 출력합니다\n",
    "    \"\"\"\n",
    "    for item in results:\n",
    "        print(\"...[%.2f] - %s\"%(item[1], item[0]))\n",
    "\n",
    "def get_closest(target_word, word_to_idx, embeddings, n =5):\n",
    "    \"\"\"\n",
    "    n개의 최근접 단어를 찾습니다.\n",
    "    \"\"\"\n",
    "\n",
    "    # 다른 모든 단어와의 거리를 계산합니다\n",
    "    word_embedding = embeddings[word_to_idx[target_word.lower()]]\n",
    "    distances = []\n",
    "    for word, index in word_to_idx.items():\n",
    "        if word == \"<MASK>\" or word == target_word:\n",
    "            continue\n",
    "        distances.append(word, torch.dist(word_embedding, embeddings[index]))\n",
    "\n",
    "    results = sorted(distances, key = lambda x: x[1])[1:n+2]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = '왕'\n",
    "embeddings = classifier.embedidng.weight.data\n",
    "word_to_idx = vectorizer.cbow_vocab._token_to_idx\n",
    "pretty_print(get_closest(word, word_to_idx, embeddings, n = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- embedding 값은 세가지 모두 될 수 있음.\n",
    "  > - 입력층의 가중치\n",
    "  > - 출력층의 가중치\n",
    "  > - 양쪽 가중치 모두 이용\n",
    "\n",
    "- Word2Vec 모델(특히 skip-gram)에서는 입력층의 가중치를 많이 사용\n",
    "- GloVe 모델에서는 두 가중치를 더해서 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reference\n",
    "- 밑바닥부터 시작하는 딥러닝2\n",
    "- 파이토치로 배우는 자연어 처리 (한빛미디어, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('book')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbb9e52b27e1643625a5b3f8a7047453142bd39b43540a1ee4af44f044e42c0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
